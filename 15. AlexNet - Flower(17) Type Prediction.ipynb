{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPFW4cuRH5Yw9EYPGQG2+aN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **AlexNet - Flower(17) Type Prediction**\n","---\n","---"],"metadata":{"id":"kjmLJDbT1cAg"}},{"cell_type":"code","source":["!pip install tensorflow==2.10.0\n","!pip install tflearn\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"D2cC_I9VKjLm","executionInfo":{"status":"ok","timestamp":1694871585083,"user_tz":-330,"elapsed":15408,"user":{"displayName":"Sovan Mistry","userId":"15532168041096048337"}},"outputId":"da55aadd-cd4a-409b-c474-e152b9b66219"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow==2.10.0 in /usr/local/lib/python3.10/dist-packages (2.10.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.57.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.9.0)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.1.2)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (16.0.6)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.1)\n","Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.0)\n","  Using cached protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n","Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.33.0)\n","Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.3.7)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n","Installing collected packages: protobuf\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed protobuf-3.19.6\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tflearn in /usr/local/lib/python3.10/dist-packages (0.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tflearn) (1.23.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tflearn) (1.16.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tflearn) (9.4.0)\n"]}]},{"cell_type":"code","source":["!pip install protobuf==3.20.3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"VeF5VR4GLGl9","executionInfo":{"status":"ok","timestamp":1694870839496,"user_tz":-330,"elapsed":11359,"user":{"displayName":"Sovan Mistry","userId":"15532168041096048337"}},"outputId":"c1cd7132-ef02-40b3-c1ff-795bd39072d7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting protobuf==3.20.3\n","  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: protobuf\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.19.6\n","    Uninstalling protobuf-3.19.6:\n","      Successfully uninstalled protobuf-3.19.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n","tensorflow 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed protobuf-3.20.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import BatchNormalization"],"metadata":{"id":"Rui6B4Ad1cba","executionInfo":{"status":"ok","timestamp":1694870865947,"user_tz":-330,"elapsed":5497,"user":{"displayName":"Sovan Mistry","userId":"15532168041096048337"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Get Data\n","import tflearn.datasets.oxflower17 as oxflower17\n","from keras.utils import to_categorical\n","\n","x, y = oxflower17.load_data()\n","\n","x_train = x.astype('float32') / 255.0\n","y_train = to_categorical(y, num_classes=17)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lt2fNzwR1iu1","executionInfo":{"status":"ok","timestamp":1694870902170,"user_tz":-330,"elapsed":36228,"user":{"displayName":"Sovan Mistry","userId":"15532168041096048337"}},"outputId":"0dda1bac-b111-4f06-cb60-dcdf3d12c9f7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]},{"output_type":"stream","name":"stdout","text":["Downloading Oxford 17 category Flower Dataset, Please wait...\n"]},{"output_type":"stream","name":"stderr","text":["100.0% 60276736 / 60270631\n"]},{"output_type":"stream","name":"stdout","text":["Succesfully downloaded 17flowers.tgz 60270631 bytes.\n","File Extracted\n","Starting to parse images...\n","Parsing Done!\n"]}]},{"cell_type":"code","source":["# Create a sequential model\n","model = Sequential()\n","\n","# 1st Convolutional Layer\n","model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n","model.add(Activation('relu'))\n","\n","# Pooling\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n","# Batch Normalisation before passing it to the next layer\n","model.add(BatchNormalization())\n","\n","# 2nd Convolutional Layer\n","model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n","model.add(Activation('relu'))\n","\n","# Pooling\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","\n","\n","# 3rd Convolutional Layer\n","model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n","model.add(Activation('relu'))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# 4th Convolutional Layer\n","model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n","model.add(Activation('relu'))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","\n","# 5th Convolutional Layer\n","model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n","model.add(Activation('relu'))\n","\n","\n","# Pooling\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","\n","# Passing it to a dense layer\n","model.add(Flatten())\n","\n","# 1st Dense Layer\n","model.add(Dense(4096, input_shape=(224*224*3,)))\n","model.add(Activation('relu'))\n","# Add Dropout to prevent overfitting\n","model.add(Dropout(0.4))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# 2nd Dense Layer\n","model.add(Dense(4096))\n","model.add(Activation('relu'))\n","# Add Dropout\n","model.add(Dropout(0.4))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# Output Layer\n","model.add(Dense(17))\n","model.add(Activation('softmax'))\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FwrkItQY7Fuy","executionInfo":{"status":"ok","timestamp":1694870903253,"user_tz":-330,"elapsed":1090,"user":{"displayName":"Sovan Mistry","userId":"15532168041096048337"}},"outputId":"9d8dafb8-5bb6-4269-aab5-fd529f20f467"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/normalization/batch_normalization.py:562: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 54, 54, 96)        34944     \n","                                                                 \n"," activation (Activation)     (None, 54, 54, 96)        0         \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 26, 26, 96)       0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 26, 26, 96)       384       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 26, 26, 256)       614656    \n","                                                                 \n"," activation_1 (Activation)   (None, 26, 26, 256)       0         \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 12, 12, 256)      0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 12, 12, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 10, 10, 384)       885120    \n","                                                                 \n"," activation_2 (Activation)   (None, 10, 10, 384)       0         \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 10, 10, 384)      1536      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 8, 8, 384)         1327488   \n","                                                                 \n"," activation_3 (Activation)   (None, 8, 8, 384)         0         \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 8, 8, 384)        1536      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 6, 6, 256)         884992    \n","                                                                 \n"," activation_4 (Activation)   (None, 6, 6, 256)         0         \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 2, 2, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 2, 2, 256)        1024      \n"," hNormalization)                                                 \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 4096)              4198400   \n","                                                                 \n"," activation_5 (Activation)   (None, 4096)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 4096)              0         \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 4096)             16384     \n"," hNormalization)                                                 \n","                                                                 \n"," dense_1 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," activation_6 (Activation)   (None, 4096)              0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 4096)             16384     \n"," hNormalization)                                                 \n","                                                                 \n"," dense_2 (Dense)             (None, 17)                69649     \n","                                                                 \n"," activation_7 (Activation)   (None, 17)                0         \n","                                                                 \n","=================================================================\n","Total params: 24,834,833\n","Trainable params: 24,815,697\n","Non-trainable params: 19,136\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"Fj6TuKfO76Td","executionInfo":{"status":"ok","timestamp":1694870903253,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sovan Mistry","userId":"15532168041096048337"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Train\n","model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=1,validation_split=0.2, shuffle=True)"],"metadata":{"id":"1xdBJYE1832E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694871568611,"user_tz":-330,"elapsed":665361,"user":{"displayName":"Sovan Mistry","userId":"15532168041096048337"}},"outputId":"58628c9f-9a38-4969-912e-a87e57e84992"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 1088 samples, validate on 272 samples\n","Epoch 1/5\n","1088/1088 [==============================] - ETA: 0s - loss: 3.5623 - acc: 0.2463"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1088/1088 [==============================] - 134s 123ms/sample - loss: 3.5623 - acc: 0.2463 - val_loss: 3.0416 - val_acc: 0.0441\n","Epoch 2/5\n","1088/1088 [==============================] - 136s 125ms/sample - loss: 2.4367 - acc: 0.3980 - val_loss: 4.2450 - val_acc: 0.0478\n","Epoch 3/5\n","1088/1088 [==============================] - 133s 122ms/sample - loss: 1.7418 - acc: 0.4899 - val_loss: 5.5605 - val_acc: 0.0478\n","Epoch 4/5\n","1088/1088 [==============================] - 130s 120ms/sample - loss: 1.4788 - acc: 0.5358 - val_loss: 5.2494 - val_acc: 0.0735\n","Epoch 5/5\n","1088/1088 [==============================] - 130s 120ms/sample - loss: 1.2120 - acc: 0.6232 - val_loss: 5.8968 - val_acc: 0.0478\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff635568af0>"]},"metadata":{},"execution_count":5}]}]}